---
title: 我用这个方法，5秒看了120篇文章。

tags: 鸽子

excerpt: 想要文章读的快，光靠眼睛可不行。

---

![](https://navtool.gitee.io/blog/assets/imgs/20220822/3.8.jpg)


> 哈喽，大家好，我是程小南，导航搬砖工一名，致力于为大家淘出更多有趣好使的生产力工具，力争成为导航爸爸！

美好的一天结束啦~

指南君开心的收拾着桌面，下班啦！

刚起身，就看对面工位上大力的电脑屏散发着神
~~（jia ban）~~圣~~（gou）~~的光~~（ri）~~芒~~（chang）~~

走进一看，大力扒着**Word2Vec**文档，满脸“一言难尽”的表情。

问了问，原来这兄弟看到女神每天辛辛苦苦对比文章相似度，心疼不已。

所以大力这个JAVA大汉，这会儿就在拜读自然语言处理工具，小南是看不下去了，赶紧想办法让兄弟快速入门。

### Word2Vec的由来
Word2Vec诞生于2013年，由Google开源问世。

是一款计算词向量的工具。在这里我们需要辨析的是：Word2Vec不是一个算法，而是计算词向量的工具。

因此，就有了一种简单理解：Word2Vec工具其实是基于CBoW模型和Skip-gram模型的计算词向量的工具。

那么没有接触过自然语言处理的童鞋一定会好奇：“词向量又是什么呢？”

小南视图将词向量简单的解释出来，以便理解。

小南在这里用一个例子尝试说明：

::: block-1
### 问题：西安 - 陕西 + 江苏 = ？

> 简单从人的角度出发来看，西安是陕西的省会，“西安”减去“陕西”等于“省会”，“省会”加上“江苏”大概率指的就是“南京”了。

> 但是机器很难分析出“南京”这个结果，为了帮助机器理解文字，需要想办法将文字以数学的形式表达出来。
> 因此我们引入的向量的概念，因为向量是可以进行加减的，所以会将文字转化为词语，再转化为向量，由此而来了一种可以分析文字的方法。
:::

说了这么多，再来看对Word2Vec的简单定义：**Word2Vec工具其实是基于CBoW模型和Skip-gram模型的计算词向量的工具。**是不是就更清楚了嘞？

### Word2Vec的安装
接下来我们就看一下：Word2Vec的安装.

方法1. 可以安装gensim，因为gensim是一个工具箱，里面包含了Word2Vex：

```pip install gensim```

方法2. 也可以直接安装Word2Vex。需要注意的是安装word2vec需要gcc依赖，如果没有gcc的话，会安装失败。

```pip install Word2Vex```


**注意，安装Word2Vex前需要安装：**
1. 安装gcc

不然报错：error：could not build wheels for word2vec， which is required to install pyproject.toml-based project
  
2. 安装Microsoft Visual C++ 14.0

不然报错：error: Microsoft Visual C++ 14.0 or greater is required. Get it with “Microsoft C++ Build Tools“: h
  
3. 安装numpy、scipy，使用pip install即可

### Word2Vec的使用

本案例安装的版本为Word2Vec 0.11.1：

```
from gensim.models import Word2Vec
from gensim.models.word2vec import LineSentence
import numpy as np

# sentence = LineSentence("content.txt")  #如果语料是文件，可以使用LineSentence准备训练语料
sentence = [["小明", "今天", "要", "去", '少年宫', "游泳"]]  # 准备训练预料
model = Word2Vec(sentences = sentence, vector_size=5, window=5, min_count=1, workers=4) # 生成模型
word_vectors = model.wv['小明'] # 输出词语的向量映射
print(word_vectors) # [-0.06810732 -0.01892805  0.11537147 -0.15043278 -0.0787221 ]
moresentence = [["小明", "和", "小明", "哥哥", "不要", "去", '少年宫', "游泳"]] # 准备训练预料
model.train(corpus_iterable = moresentence, epochs = 1, total_words = 1) # 训练模型
model.save('train_demo.model') # 保存模型
model = Word2Vec.load('train_demo.model')  # 加载模型
# 使用模型
result = model.wv.most_similar(positive=['今天', '游泳'], negative=['少年宫'], topn=2) # 使用模型找出相近的10个词，'今天', '游泳'对相似性有正面贡献，'少年宫'有负面贡献
print(result) # [('去', 0.714894711971283), ('要', -0.5734316110610962)]
distance = model.wv.distance("少年宫", "小明") # 两个单词的距离
print(distance) # 0.22581267356872559
```
最终的使用方法以源码为主，源码中有备注案例，大家可以查看。

- 建立模型具体参数：可以看源码
```
	  class Word2Vec(utils.SaveLoad):
		    def __init__(
		            self, sentences=None, corpus_file=None, vector_size=100, alpha=0.025, window=5, min_count=5,
		            max_vocab_size=None, sample=1e-3, seed=1, workers=3, min_alpha=0.0001,
		            sg=0, hs=0, negative=5, ns_exponent=0.75, cbow_mean=1, hashfxn=hash, epochs=5, null_word=0,
		            trim_rule=None, sorted_vocab=1, batch_words=MAX_WORDS_IN_BATCH, compute_loss=False, callbacks=(),
		            comment=None, max_final_vocab=None, shrink_windows=True,
		        ):
```

### 程小南有话说

自然语言处理中，对于文本分析有很多的工具可以使用，小南经常喜欢做案例，并多对模型进行训练，选取最适合自己的。

大家有好用的训练工具、方法欢迎在评论区讨论哦。

### 好消息
程序员指南读者群开放啦！！！欢迎各位读者进群，群内以聊天学习摸鱼为主，不定期分享好玩有趣的优秀工具。

进群方式：公众号后台回复`进群`，按提示操作即可进群。

![](https://navtool.gitee.io/blog/assets/imgs/erweima.jpg)

### 更多好用工具
想知道更多的好玩工具，实用网站，欢迎访问[程序员一站式导航](http://www.cxy521.com/)(www.cxy521.com)，简洁实用有趣的工具应有尽有。

![](https://navtool.gitee.io/blog/assets/imgs/20220329/img.png)

如果你也有压箱底的神器、好用的开发工具分享欢迎在留言区和我们留言讨论。

> 我是程小南,感谢各位童鞋的：点赞、收藏和在看，我们下期更精彩！
